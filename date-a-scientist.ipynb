{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "import re\n",
    "from part_of_speech import get_part_of_speech\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['age', 'body_type', 'diet', 'drinks', 'drugs', 'education', 'essay0',\n",
       "       'essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6', 'essay7',\n",
       "       'essay8', 'essay9', 'ethnicity', 'height', 'income', 'job',\n",
       "       'last_online', 'location', 'offspring', 'orientation', 'pets',\n",
       "       'religion', 'sex', 'sign', 'smokes', 'speaks', 'status'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "df = pd.read_csv('../okcupiddata/profiles.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              essay0  \\\n",
       "0  about me:<br />\\n<br />\\ni would love to think...   \n",
       "1  i am a chef: this is what that means.<br />\\n1...   \n",
       "2  i'm not ashamed of much, but writing public te...   \n",
       "3          i work in a library and go to school. . .   \n",
       "4  hey how's it going? currently vague on the pro...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  currently working as an international agent fo...   \n",
       "1  dedicating everyday to being an unbelievable b...   \n",
       "2  i make nerdy software for musicians, artists, ...   \n",
       "3          reading things written by old dead people   \n",
       "4                         work work work work + play   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  making people laugh.<br />\\nranting about a go...   \n",
       "1  being silly. having ridiculous amonts of fun w...   \n",
       "2  improvising in different contexts. alternating...   \n",
       "3  playing synthesizers and organizing books acco...   \n",
       "4  creating imagery to look at:<br />\\nhttp://bag...   \n",
       "\n",
       "                                              essay3  \\\n",
       "0  the way i look. i am a six foot half asian, ha...   \n",
       "1                                                NaN   \n",
       "2  my large jaw and large glasses are the physica...   \n",
       "3                  socially awkward but i do my best   \n",
       "4            i smile a lot and my inquisitive nature   \n",
       "\n",
       "                                              essay4  \\\n",
       "0  books:<br />\\nabsurdistan, the republic, of mi...   \n",
       "1  i am die hard christopher moore fan. i don't r...   \n",
       "2  okay this is where the cultural matrix gets so...   \n",
       "3  bataille, celine, beckett. . .<br />\\nlynch, j...   \n",
       "4  music: bands, rappers, musicians<br />\\nat the...   \n",
       "\n",
       "                                              essay5  \\\n",
       "0  food.<br />\\nwater.<br />\\ncell phone.<br />\\n...   \n",
       "1  delicious porkness in all of its glories.<br /...   \n",
       "2  movement<br />\\nconversation<br />\\ncreation<b...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                        essay6  \\\n",
       "0  duality and humorous things   \n",
       "1                          NaN   \n",
       "2                          NaN   \n",
       "3   cats and german philosophy   \n",
       "4                          NaN   \n",
       "\n",
       "                                              essay7  \\\n",
       "0  trying to find someone to hang out with. i am ...   \n",
       "1                                                NaN   \n",
       "2  viewing. listening. dancing. talking. drinking...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              essay8  \\\n",
       "0  i am new to california and looking for someone...   \n",
       "1  i am very open and will share just about anyth...   \n",
       "2  when i was five years old, i was known as \"the...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              essay9  \n",
       "0  you want to be swept off your feet!<br />\\nyou...  \n",
       "1                                                NaN  \n",
       "2  you are bright, open, intense, silly, ironic, ...  \n",
       "3                              you feel so inclined.  \n",
       "4                                                NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>essay0</th>\n      <th>essay1</th>\n      <th>essay2</th>\n      <th>essay3</th>\n      <th>essay4</th>\n      <th>essay5</th>\n      <th>essay6</th>\n      <th>essay7</th>\n      <th>essay8</th>\n      <th>essay9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>about me:&lt;br /&gt;\\n&lt;br /&gt;\\ni would love to think...</td>\n      <td>currently working as an international agent fo...</td>\n      <td>making people laugh.&lt;br /&gt;\\nranting about a go...</td>\n      <td>the way i look. i am a six foot half asian, ha...</td>\n      <td>books:&lt;br /&gt;\\nabsurdistan, the republic, of mi...</td>\n      <td>food.&lt;br /&gt;\\nwater.&lt;br /&gt;\\ncell phone.&lt;br /&gt;\\n...</td>\n      <td>duality and humorous things</td>\n      <td>trying to find someone to hang out with. i am ...</td>\n      <td>i am new to california and looking for someone...</td>\n      <td>you want to be swept off your feet!&lt;br /&gt;\\nyou...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i am a chef: this is what that means.&lt;br /&gt;\\n1...</td>\n      <td>dedicating everyday to being an unbelievable b...</td>\n      <td>being silly. having ridiculous amonts of fun w...</td>\n      <td>NaN</td>\n      <td>i am die hard christopher moore fan. i don't r...</td>\n      <td>delicious porkness in all of its glories.&lt;br /...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>i am very open and will share just about anyth...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i'm not ashamed of much, but writing public te...</td>\n      <td>i make nerdy software for musicians, artists, ...</td>\n      <td>improvising in different contexts. alternating...</td>\n      <td>my large jaw and large glasses are the physica...</td>\n      <td>okay this is where the cultural matrix gets so...</td>\n      <td>movement&lt;br /&gt;\\nconversation&lt;br /&gt;\\ncreation&lt;b...</td>\n      <td>NaN</td>\n      <td>viewing. listening. dancing. talking. drinking...</td>\n      <td>when i was five years old, i was known as \"the...</td>\n      <td>you are bright, open, intense, silly, ironic, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i work in a library and go to school. . .</td>\n      <td>reading things written by old dead people</td>\n      <td>playing synthesizers and organizing books acco...</td>\n      <td>socially awkward but i do my best</td>\n      <td>bataille, celine, beckett. . .&lt;br /&gt;\\nlynch, j...</td>\n      <td>NaN</td>\n      <td>cats and german philosophy</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>you feel so inclined.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>hey how's it going? currently vague on the pro...</td>\n      <td>work work work work + play</td>\n      <td>creating imagery to look at:&lt;br /&gt;\\nhttp://bag...</td>\n      <td>i smile a lot and my inquisitive nature</td>\n      <td>music: bands, rappers, musicians&lt;br /&gt;\\nat the...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "#make dataframe just containing essays\n",
    "df_essays = df[['essay0', 'essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6', 'essay7', 'essay8', 'essay9']]\n",
    "#df_essays['corpus'] = df_essays[df_essays.columns[0:]].apply(\n",
    "#    lambda x: ','.join(x.dropna().astype(str)),\n",
    "#    axis=1)\n",
    "df_essays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "def remove_noise(text):\n",
    "    #remove html tags\n",
    "    text = text.str.replace(r'<[^<]+?>', '')\n",
    "    #remove punctuation\n",
    "    text = text.str.replace(r'[\\.\\?\\!\\,\\:\\;\\\"]', '')\n",
    "    #remove newline, tab\n",
    "    text = text.str.replace(r'\\r+|\\n+|\\t+',' ')\n",
    "    return text\n",
    "\n",
    "def tokenize_lemmatize_remove_stop(text):\n",
    "    tokenized = word_tokenize(str(text))\n",
    "    #print(tokenized)\n",
    "    lemmatized = [lemmatizer.lemmatize(token, get_part_of_speech(token)) for token in tokenized]\n",
    "    no_stop = [word for word in lemmatized if word not in stop_words]\n",
    "    return no_stop\n",
    "\n",
    "denoised = df_essays.apply(lambda row: remove_noise(row))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "denoised = pd.DataFrame(denoised)\n",
    "normalized = denoised.apply(lambda row: tokenize_lemmatize_remove_stop(row))\n",
    "normalized = pd.DataFrame(normalized)\n",
    "\n",
    "print(len(normalized[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "59946\n"
     ]
    }
   ],
   "source": [
    "print(len(denoised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd0dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}